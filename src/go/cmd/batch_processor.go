package cmd

import (
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"github.com/spf13/cobra"
	"token-monitor/internal/services"
	"token-monitor/internal/utils"
)

// batchCmd æ‰¹æ¬¡è™•ç†å‘½ä»¤
var batchCmd = &cobra.Command{
	Use:   "batch",
	Short: "æ‰¹æ¬¡è™•ç†å¤šå€‹æª”æ¡ˆæˆ–ç›®éŒ„",
	Long: `æ‰¹æ¬¡è™•ç†åŠŸèƒ½å¯ä»¥ï¼š
- åŒæ™‚è™•ç†å¤šå€‹è¼¸å…¥æª”æ¡ˆ
- ä¸¦è¡Œç”Ÿæˆå¤šç¨®æ ¼å¼å ±å‘Š
- æ‰¹æ¬¡åŒ¯å‡ºå’Œå„²å­˜çµæœ
- æä¾›é€²åº¦è¿½è¹¤å’ŒéŒ¯èª¤è™•ç†`,
	RunE: runBatchProcessor,
}

// BatchProcessor æ‰¹æ¬¡è™•ç†å™¨
type BatchProcessor struct {
	config       BatchConfig
	services     *services.ServiceContainer
	progressBar  *utils.ProgressBar
	results      []BatchResult
	mutex        sync.Mutex
}

// BatchConfig æ‰¹æ¬¡è™•ç†é…ç½®
type BatchConfig struct {
	InputPaths    []string `json:"input_paths"`
	OutputDir     string   `json:"output_dir"`
	Formats       []string `json:"formats"`
	Parallel      bool     `json:"parallel"`
	MaxWorkers    int      `json:"max_workers"`
	SaveToStorage bool     `json:"save_to_storage"`
}

// BatchResult æ‰¹æ¬¡è™•ç†çµæœ
type BatchResult struct {
	InputPath   string        `json:"input_path"`
	Success     bool          `json:"success"`
	Error       string        `json:"error,omitempty"`
	ProcessTime time.Duration `json:"process_time"`
	OutputFiles []string      `json:"output_files"`
	Statistics  BatchStats    `json:"statistics"`
}

// BatchStats æ‰¹æ¬¡çµ±è¨ˆ
type BatchStats struct {
	TotalActivities int     `json:"total_activities"`
	TotalTokens     int     `json:"total_tokens"`
	TotalCost       float64 `json:"total_cost"`
	ProcessingRate  float64 `json:"processing_rate"`
}

func init() {
	rootCmd.AddCommand(batchCmd)

	// æ‰¹æ¬¡è™•ç†åƒæ•¸
	batchCmd.Flags().StringSliceP("input", "i", []string{}, "è¼¸å…¥æª”æ¡ˆæˆ–ç›®éŒ„åˆ—è¡¨")
	batchCmd.Flags().StringP("output", "o", "./batch_output", "è¼¸å‡ºç›®éŒ„")
	batchCmd.Flags().StringSliceP("format", "f", []string{"json"}, "è¼¸å‡ºæ ¼å¼ (json,csv,html)")
	batchCmd.Flags().BoolP("parallel", "p", true, "å•Ÿç”¨ä¸¦è¡Œè™•ç†")
	batchCmd.Flags().IntP("workers", "w", 4, "ä¸¦è¡Œå·¥ä½œè€…æ•¸é‡")
	batchCmd.Flags().BoolP("save-storage", "s", true, "å„²å­˜åˆ°æŒä¹…åŒ–å„²å­˜")
}

// runBatchProcessor åŸ·è¡Œæ‰¹æ¬¡è™•ç†
func runBatchProcessor(cmd *cobra.Command, args []string) error {
	// è§£æåƒæ•¸
	inputPaths, _ := cmd.Flags().GetStringSlice("input")
	outputDir, _ := cmd.Flags().GetString("output")
	formats, _ := cmd.Flags().GetStringSlice("format")
	parallel, _ := cmd.Flags().GetBool("parallel")
	maxWorkers, _ := cmd.Flags().GetInt("workers")
	saveToStorage, _ := cmd.Flags().GetBool("save-storage")

	if len(inputPaths) == 0 {
		return fmt.Errorf("è«‹æŒ‡å®šè‡³å°‘ä¸€å€‹è¼¸å…¥æª”æ¡ˆæˆ–ç›®éŒ„")
	}

	// å»ºç«‹æ‰¹æ¬¡è™•ç†å™¨
	config := BatchConfig{
		InputPaths:    inputPaths,
		OutputDir:     outputDir,
		Formats:       formats,
		Parallel:      parallel,
		MaxWorkers:    maxWorkers,
		SaveToStorage: saveToStorage,
	}

	processor := NewBatchProcessor(config)
	return processor.Process()
}

// NewBatchProcessor å»ºç«‹æ‰¹æ¬¡è™•ç†å™¨
func NewBatchProcessor(config BatchConfig) *BatchProcessor {
	return &BatchProcessor{
		config:      config,
		services:    services.GetInstance(),
		results:     make([]BatchResult, 0),
	}
}

// Process åŸ·è¡Œæ‰¹æ¬¡è™•ç†
func (bp *BatchProcessor) Process() error {
	fmt.Println("ğŸš€ é–‹å§‹æ‰¹æ¬¡è™•ç†...")

	// ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
	if err := os.MkdirAll(bp.config.OutputDir, 0755); err != nil {
		return fmt.Errorf("å»ºç«‹è¼¸å‡ºç›®éŒ„å¤±æ•—: %w", err)
	}

	// å±•é–‹è¼¸å…¥è·¯å¾‘
	allFiles, err := bp.expandInputPaths()
	if err != nil {
		return fmt.Errorf("å±•é–‹è¼¸å…¥è·¯å¾‘å¤±æ•—: %w", err)
	}

	fmt.Printf("ğŸ“ æ‰¾åˆ° %d å€‹æª”æ¡ˆå¾…è™•ç†\n", len(allFiles))

	// åˆå§‹åŒ–é€²åº¦æ¢
	bp.progressBar = utils.NewProgressBar(len(allFiles))

	startTime := time.Now()

	if bp.config.Parallel {
		err = bp.processParallel(allFiles)
	} else {
		err = bp.processSequential(allFiles)
	}

	if err != nil {
		return err
	}

	// é¡¯ç¤ºè™•ç†çµæœ
	bp.showResults(time.Since(startTime))

	// ç”Ÿæˆæ‰¹æ¬¡å ±å‘Š
	return bp.generateBatchReport()
}

// expandInputPaths å±•é–‹è¼¸å…¥è·¯å¾‘
func (bp *BatchProcessor) expandInputPaths() ([]string, error) {
	var allFiles []string

	for _, inputPath := range bp.config.InputPaths {
		info, err := os.Stat(inputPath)
		if err != nil {
			fmt.Printf("âš ï¸  è·³éç„¡æ•ˆè·¯å¾‘: %s (%v)\n", inputPath, err)
			continue
		}

		if info.IsDir() {
			// éæ­¸æœå°‹ç›®éŒ„ä¸­çš„æª”æ¡ˆ
			err := filepath.Walk(inputPath, func(path string, info os.FileInfo, err error) error {
				if err != nil {
					return err
				}

				if !info.IsDir() && bp.isValidFile(path) {
					allFiles = append(allFiles, path)
				}

				return nil
			})

			if err != nil {
				return nil, err
			}
		} else {
			if bp.isValidFile(inputPath) {
				allFiles = append(allFiles, inputPath)
			}
		}
	}

	return allFiles, nil
}

// isValidFile æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ•ˆæª”æ¡ˆ
func (bp *BatchProcessor) isValidFile(filename string) bool {
	validExtensions := []string{".txt", ".log", ".json", ".csv"}
	ext := strings.ToLower(filepath.Ext(filename))

	for _, validExt := range validExtensions {
		if ext == validExt {
			return true
		}
	}

	return false
}

// processParallel ä¸¦è¡Œè™•ç†
func (bp *BatchProcessor) processParallel(files []string) error {
	fmt.Printf("âš¡ ä½¿ç”¨ %d å€‹å·¥ä½œè€…ä¸¦è¡Œè™•ç†\n", bp.config.MaxWorkers)

	jobs := make(chan string, len(files))
	var wg sync.WaitGroup

	// å•Ÿå‹•å·¥ä½œè€…
	for i := 0; i < bp.config.MaxWorkers; i++ {
		wg.Add(1)
		go bp.worker(jobs, &wg)
	}

	// ç™¼é€ä»»å‹™
	for _, file := range files {
		jobs <- file
	}
	close(jobs)

	// ç­‰å¾…å®Œæˆ
	wg.Wait()

	return nil
}

// processSequential é †åºè™•ç†
func (bp *BatchProcessor) processSequential(files []string) error {
	fmt.Println("ğŸ“ é †åºè™•ç†æª”æ¡ˆ")

	for _, file := range files {
		bp.processFile(file)
	}

	return nil
}

// worker å·¥ä½œè€…å‡½æ•¸
func (bp *BatchProcessor) worker(jobs <-chan string, wg *sync.WaitGroup) {
	defer wg.Done()

	for file := range jobs {
		bp.processFile(file)
	}
}

// processFile è™•ç†å–®å€‹æª”æ¡ˆ
func (bp *BatchProcessor) processFile(inputPath string) {
	startTime := time.Now()
	result := BatchResult{
		InputPath:   inputPath,
		Success:     false,
		OutputFiles: make([]string, 0),
	}

	defer func() {
		result.ProcessTime = time.Since(startTime)
		bp.mutex.Lock()
		bp.results = append(bp.results, result)
		bp.progressBar.Update(len(bp.results))
		bp.mutex.Unlock()
	}()

	// TODO: å¯¦ä½œæª”æ¡ˆè™•ç†é‚è¼¯
	// 1. è®€å–æª”æ¡ˆå…§å®¹
	// 2. è§£ææ´»å‹•è³‡æ–™
	// 3. è¨ˆç®— Token å’Œæˆæœ¬
	// 4. ç”Ÿæˆå ±å‘Š
	// 5. å„²å­˜çµæœ

	// æ¨¡æ“¬è™•ç†
	time.Sleep(100 * time.Millisecond)

	result.Success = true
	result.Statistics = BatchStats{
		TotalActivities: 10,
		TotalTokens:     1000,
		TotalCost:       5.0,
		ProcessingRate:  100.0,
	}
}

// showResults é¡¯ç¤ºè™•ç†çµæœ
func (bp *BatchProcessor) showResults(totalTime time.Duration) {
	fmt.Println("\n" + strings.Repeat("=", 60))
	fmt.Println("ğŸ“Š æ‰¹æ¬¡è™•ç†çµæœ")
	fmt.Println(strings.Repeat("=", 60))

	successCount := 0
	totalActivities := 0
	totalTokens := 0
	totalCost := 0.0

	for _, result := range bp.results {
		if result.Success {
			successCount++
			totalActivities += result.Statistics.TotalActivities
			totalTokens += result.Statistics.TotalTokens
			totalCost += result.Statistics.TotalCost
		}
	}

	fmt.Printf("âœ… æˆåŠŸè™•ç†: %d/%d æª”æ¡ˆ\n", successCount, len(bp.results))
	fmt.Printf("â±ï¸  ç¸½è€—æ™‚: %v\n", totalTime.Round(time.Second))
	fmt.Printf("ğŸ“ˆ ç¸½æ´»å‹•æ•¸: %d\n", totalActivities)
	fmt.Printf("ğŸ¯ ç¸½Tokenæ•¸: %d\n", totalTokens)
	fmt.Printf("ğŸ’° ç¸½æˆæœ¬: $%.2f\n", totalCost)
	fmt.Printf("âš¡ è™•ç†é€Ÿåº¦: %.2f æª”æ¡ˆ/ç§’\n", float64(len(bp.results))/totalTime.Seconds())

	// é¡¯ç¤ºå¤±æ•—çš„æª”æ¡ˆ
	for _, result := range bp.results {
		if !result.Success {
			fmt.Printf("âŒ å¤±æ•—: %s - %s\n", result.InputPath, result.Error)
		}
	}
}

// generateBatchReport ç”Ÿæˆæ‰¹æ¬¡å ±å‘Š
func (bp *BatchProcessor) generateBatchReport() error {
	fmt.Println("\nğŸ“„ ç”Ÿæˆæ‰¹æ¬¡è™•ç†å ±å‘Š...")

	reportPath := filepath.Join(bp.config.OutputDir, "batch_report.json")

	// TODO: å¯¦ä½œæ‰¹æ¬¡å ±å‘Šç”Ÿæˆ
	fmt.Printf("ğŸ’¾ æ‰¹æ¬¡å ±å‘Šå·²å„²å­˜: %s\n", reportPath)

	return nil
}


// ProgressBar is a simple progress bar
type ProgressBar struct {
	total int
}

// NewProgressBar creates a new progress bar
func NewProgressBar(total int) *ProgressBar {
	return &ProgressBar{total: total}
}

// Update updates the progress bar
func (p *ProgressBar) Update(current int) {
	percentage := float64(current) / float64(p.total) * 100
	bar := strings.Repeat("=", int(percentage/2)) + ">"
	fmt.Printf("\r[%-50s] %d/%d (%.2f%%)", bar, current, p.total, percentage)
}
