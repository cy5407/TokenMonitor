package calculator

import (
	"fmt"
	"runtime"
	"strings"
	"sync"
	"testing"
	"time"
	"unicode/utf8"
)

// TestExtendedUnicodeSupport æ¸¬è©¦æ“´å±•çš„ Unicode å­—ç¬¦æ”¯æ´
func TestExtendedUnicodeSupport(t *testing.T) {
	calculator := NewTokenCalculator(1000)

	testCases := []struct {
		name        string
		text        string
		description string
	}{
		{
			name:        "Emojié›†åˆ",
			text:        "ğŸš€ğŸ‰ğŸ”¥ğŸ’¯âœ¨ğŸŒŸâ­ï¸ğŸ¯ğŸ†ğŸŠ",
			description: "å„ç¨® emoji å­—ç¬¦",
		},
		{
			name:        "æ•¸å­¸ç¬¦è™Ÿ",
			text:        "âˆ‘âˆâˆ«âˆÂ±âˆšâˆ†âˆ‡âˆ‚âˆƒâˆ€âˆˆâˆ‰âŠ‚âŠƒâˆªâˆ©",
			description: "æ•¸å­¸å’Œç§‘å­¸ç¬¦è™Ÿ",
		},
		{
			name:        "è²¨å¹£ç¬¦è™Ÿ",
			text:        "Â¥â‚¬Â£$Â¢â‚¹â‚©â‚½â‚¨â‚ªâ‚«â‚¦â‚¡â‚µâ‚¸â‚´â‚¯â‚¶",
			description: "ä¸–ç•Œå„åœ‹è²¨å¹£ç¬¦è™Ÿ",
		},
		{
			name:        "ç®­é ­ç¬¦è™Ÿ",
			text:        "â†â†’â†‘â†“â†”â†•â†–â†—â†˜â†™â‡â‡’â‡‘â‡“â‡”â‡•",
			description: "å„ç¨®ç®­é ­ç¬¦è™Ÿ",
		},
		{
			name:        "å¹¾ä½•ç¬¦è™Ÿ",
			text:        "â–³â–²â–½â–¼â—‡â—†â–¡â– â—‹â—â—¯â—â˜…â˜†",
			description: "å¹¾ä½•åœ–å½¢ç¬¦è™Ÿ",
		},
		{
			name:        "å¤šèªè¨€æ–‡å­—",
			text:        "Î•Î»Î»Î·Î½Î¹ÎºÎ¬ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© í•œêµ­ì–´ æ—¥æœ¬èª Ñ€ÑƒÑÑĞºĞ¸Ğ¹ à¤¹à¤¿à¤¨à¥à¤¦à¥€ ×¢×‘×¨×™×ª",
			description: "å¸Œè‡˜èªã€é˜¿æ‹‰ä¼¯èªã€éŸ“èªã€æ—¥èªã€ä¿„èªã€å°åœ°èªã€å¸Œä¼¯ä¾†èª",
		},
		{
			name:        "çµ„åˆå­—ç¬¦",
			text:        "cafÃ© naÃ¯ve rÃ©sumÃ© piÃ±ata maÃ±ana",
			description: "åŒ…å«é‡éŸ³ç¬¦è™Ÿçš„æ‹‰ä¸å­—ç¬¦",
		},
		{
			name:        "ä¸­æ–‡ç¹ç°¡æ··åˆ",
			text:        "ç¹é«”ä¸­æ–‡å’Œç®€ä½“ä¸­æ–‡æ··åˆåœ¨ä¸€èµ·çš„æ–‡å­—å…§å®¹",
			description: "ç¹é«”å’Œç°¡é«”ä¸­æ–‡æ··åˆ",
		},
		{
			name:        "ç‰¹æ®Šç©ºç™½å­—ç¬¦",
			text:        "æ™®é€šç©ºæ ¼ \u00A0 ä¸æ–·è¡Œç©ºæ ¼ \u2000 å››åˆ†ä¹‹ä¸€ç©ºæ ¼ \u2003 å…¨å½¢ç©ºæ ¼",
			description: "å„ç¨®Unicodeç©ºç™½å­—ç¬¦",
		},
		{
			name:        "é›¶å¯¬åº¦å­—ç¬¦",
			text:        "zero\u200Bwidth\u200Cjoiner\u200Dtest\uFEFF",
			description: "é›¶å¯¬åº¦ç©ºæ ¼ã€éé€£æ¥ç¬¦ã€é€£æ¥ç¬¦ã€ä½å…ƒçµ„é †åºæ¨™è¨˜",
		},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			// æ¸¬è©¦ä¼°ç®—æ–¹æ³•
			tokens, err := calculator.CalculateTokens(tc.text, "estimation")
			if err != nil {
				t.Errorf("ä¼°ç®—æ–¹æ³•å¤±æ•—: %v", err)
				return
			}

			// é©—è­‰åŸºæœ¬æ€§è³ª
			if tokens <= 0 {
				t.Errorf("Unicode æ–‡æœ¬æ‡‰è©²ç”¢ç”Ÿæ­£æ•¸ tokenï¼Œå¾—åˆ°: %d", tokens)
			}

			// æ¸¬è©¦ tiktoken æ–¹æ³•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
			if calculator.IsTiktokenAvailable() {
				tiktokenTokens, err := calculator.CalculateTokens(tc.text, "tiktoken")
				if err != nil {
					t.Errorf("Tiktoken æ–¹æ³•å¤±æ•—: %v", err)
					return
				}

				if tiktokenTokens <= 0 {
					t.Errorf("Tiktoken æ‡‰è©²ç”¢ç”Ÿæ­£æ•¸ tokenï¼Œå¾—åˆ°: %d", tiktokenTokens)
				}

				t.Logf("%s: ä¼°ç®—=%d, tiktoken=%d - %s", 
					tc.name, tokens, tiktokenTokens, tc.description)
			} else {
				t.Logf("%s: ä¼°ç®—=%d - %s", tc.name, tokens, tc.description)
			}

			// æ¸¬è©¦æ–‡æœ¬é©—è­‰
			if calcImpl, ok := calculator.(*TokenCalculatorImpl); ok {
				err := calcImpl.ValidateText(tc.text)
				if err != nil {
					t.Errorf("æ–‡æœ¬é©—è­‰å¤±æ•—: %v", err)
				}
			}
		})
	}
}

// TestComplexMixedLanguageTexts æ¸¬è©¦è¤‡é›œçš„å¤šèªè¨€æ··åˆæ–‡æœ¬
func TestComplexMixedLanguageTexts(t *testing.T) {
	calculator := NewTokenCalculator(1000)

	complexTexts := []struct {
		name string
		text string
	}{
		{
			name: "æŠ€è¡“æ–‡æª”æ··åˆ",
			text: "é€™æ˜¯ä¸€å€‹ä½¿ç”¨ React.js é–‹ç™¼çš„æ‡‰ç”¨ç¨‹å¼ã€‚function App() { return <div>Hello World</div>; } ä»£ç¢¼ä¸­ä½¿ç”¨äº† JSX èªæ³•ã€‚",
		},
		{
			name: "å•†æ¥­å ±å‘Šæ··åˆ",
			text: "2024å¹´ç¬¬ä¸€å­£åº¦çš„ç‡Ÿæ”¶é”åˆ° $1,234,567 USDï¼Œç›¸æ¯”å»å¹´åŒæœŸå¢é•·äº† 15.7%ã€‚ä¸»è¦å¢é•·ä¾†æºæ–¼äºå¤ªåœ°å€çš„æ¥­å‹™æ“´å±•ã€‚",
		},
		{
			name: "å­¸è¡“è«–æ–‡æ··åˆ",
			text: "Based on our research, we found that æ©Ÿå™¨å­¸ç¿’æ¨¡å‹åœ¨è™•ç†ä¸­æ–‡è‡ªç„¶èªè¨€æ™‚ï¼Œéœ€è¦è€ƒæ…® tokenization çš„ç‰¹æ®Šæ€§ã€‚The accuracy improved by 23.5%.",
		},
		{
			name: "ç¨‹å¼ç¢¼è¨»è§£æ··åˆ",
			text: "// é€™æ˜¯ä¸€å€‹è¨ˆç®— token æ•¸é‡çš„å‡½æ•¸\nfunction calculateTokens(text: string): number {\n  // ä½¿ç”¨æ­£è¦è¡¨é”å¼åˆ†å‰²æ–‡æœ¬\n  return text.split(/\\s+/).length;\n}",
		},
		{
			name: "JSONé…ç½®æª”æ¡ˆ",
			text: `{
  "name": "token-monitor",
  "description": "Token ç›£æ§å·¥å…·",
  "version": "1.0.0",
  "æ”¯æ´èªè¨€": ["ä¸­æ–‡", "English", "æ—¥æœ¬èª"],
  "settings": {
    "maxTokens": 4096,
    "enableCache": true
  }
}`,
		},
		{
			name: "SQLæŸ¥è©¢æ··åˆ",
			text: "SELECT ä½¿ç”¨è€…åç¨±, email FROM users WHERE è¨»å†Šæ—¥æœŸ >= '2024-01-01' AND status = 'active' ORDER BY æœ€å¾Œç™»éŒ„æ™‚é–“ DESC;",
		},
		{
			name: "éŒ¯èª¤è¨Šæ¯æ··åˆ",
			text: "Error: ç„¡æ³•é€£æ¥åˆ°è³‡æ–™åº«ã€‚Connection timeout after 30 seconds. Please check your ç¶²è·¯é€£æ¥ and try again. éŒ¯èª¤ä»£ç¢¼: DB_CONNECTION_TIMEOUT",
		},
	}

	for _, tc := range complexTexts {
		t.Run(tc.name, func(t *testing.T) {
			// æ¸¬è©¦æ‰€æœ‰æ–¹æ³•
			methods := []string{"estimation"}
			if calculator.IsTiktokenAvailable() {
				methods = append(methods, "tiktoken", "auto")
			}

			results := make(map[string]int)
			for _, method := range methods {
				tokens, err := calculator.CalculateTokens(tc.text, method)
				if err != nil {
					t.Errorf("æ–¹æ³• %s å¤±æ•—: %v", method, err)
					continue
				}
				results[method] = tokens
			}

			// æª¢æŸ¥çµæœåˆç†æ€§
			for method, tokens := range results {
				if tokens <= 0 {
					t.Errorf("æ–¹æ³• %s æ‡‰è©²ç”¢ç”Ÿæ­£æ•¸ tokenï¼Œå¾—åˆ°: %d", method, tokens)
				}
			}

			// æ¸¬è©¦ Token åˆ†ä½ˆåˆ†æ
			distribution, err := calculator.AnalyzeTokenDistribution(tc.text)
			if err != nil {
				t.Errorf("åˆ†ä½ˆåˆ†æå¤±æ•—: %v", err)
			} else {
				if distribution.TotalTokens != distribution.EnglishTokens+distribution.ChineseTokens {
					t.Errorf("Token åˆ†ä½ˆä¸ä¸€è‡´: ç¸½è¨ˆ=%d, è‹±æ–‡=%d, ä¸­æ–‡=%d",
						distribution.TotalTokens, distribution.EnglishTokens, distribution.ChineseTokens)
				}
			}

			t.Logf("%s: %+v", tc.name, results)
		})
	}
}

// TestEncodingFormats æ¸¬è©¦å„ç¨®ç·¨ç¢¼æ ¼å¼è™•ç†
func TestEncodingFormats(t *testing.T) {
	calculator := NewTokenCalculator(500)

	testCases := []struct {
		name string
		text string
	}{
		{
			name: "UTF-8 BOM",
			text: "\uFEFFé€™æ˜¯åŒ…å« BOM çš„ UTF-8 æ–‡æœ¬",
		},
		{
			name: "é›™ä½å…ƒçµ„å­—ç¬¦",
			text: "æ¸¬è©¦é›™ä½å…ƒçµ„å­—ç¬¦ï¼šÂ©Â®â„¢â‚¬Â£Â¥Â§Â¶",
		},
		{
			name: "å››ä½å…ƒçµ„å­—ç¬¦",
			text: "æ¸¬è©¦å››ä½å…ƒçµ„å­—ç¬¦ï¼šğŸŒğŸš€ğŸ’»ğŸ“±ğŸ‰",
		},
		{
			name: "ä»£ç†å°å­—ç¬¦",
			text: "æ¸¬è©¦ä»£ç†å°ï¼šğ•Šğ•¦ğ•£ğ•–ğ•£ğ•”ğ•£ğ•šğ•¡ğ•¥ ğ”¸ğ•ğ•¡ğ•™ğ•’ğ”¹ğ•–ğ•¥",
		},
		{
			name: "ç„¡æ•ˆUTF-8åºåˆ—è™•ç†",
			text: "æ­£å¸¸æ–‡æœ¬" + string([]byte{0xFF, 0xFE}) + "å¾ŒçºŒæ–‡æœ¬",
		},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			// æª¢æŸ¥æ–‡æœ¬æ˜¯å¦ç‚ºæœ‰æ•ˆçš„ UTF-8
			if !utf8.ValidString(tc.text) {
				t.Logf("è­¦å‘Š: æ–‡æœ¬åŒ…å«ç„¡æ•ˆçš„ UTF-8 åºåˆ—")
			}

			// æ¸¬è©¦åŸºæœ¬è¨ˆç®—
			tokens, err := calculator.CalculateTokens(tc.text, "estimation")
			if err != nil {
				t.Errorf("ç·¨ç¢¼è™•ç†å¤±æ•—: %v", err)
				return
			}

			if tokens <= 0 {
				t.Errorf("æ‡‰è©²ç”¢ç”Ÿæ­£æ•¸ tokenï¼Œå¾—åˆ°: %d", tokens)
			}

			// æ¸¬è©¦å­—ç¬¦è¨ˆæ•¸ä¸€è‡´æ€§
			runeCount := utf8.RuneCountInString(tc.text)
			byteCount := len(tc.text)

			t.Logf("%s: tokens=%d, runes=%d, bytes=%d", 
				tc.name, tokens, runeCount, byteCount)

			// æ¸¬è©¦æ–‡æœ¬é©—è­‰
			if calcImpl, ok := calculator.(*TokenCalculatorImpl); ok {
				err := calcImpl.ValidateText(tc.text)
				if err != nil {
					t.Logf("æ–‡æœ¬é©—è­‰è­¦å‘Š: %v", err)
				}
			}
		})
	}
}

// TestBoundaryAndEdgeCases æ¸¬è©¦é‚Šç•Œæ¢ä»¶å’Œé‚Šç·£æƒ…æ³
func TestBoundaryAndEdgeCases(t *testing.T) {
	calculator := NewTokenCalculator(100)

	testCases := []struct {
		name        string
		text        string
		expectError bool
		description string
	}{
		{
			name:        "æ¥µå¤§æ–‡æœ¬",
			text:        strings.Repeat("a", 999999), // æ¥è¿‘ 1MB é™åˆ¶
			expectError: false,
			description: "æ¥è¿‘æœ€å¤§é•·åº¦é™åˆ¶çš„æ–‡æœ¬",
		},
		{
			name:        "è¶…å¤§æ–‡æœ¬",
			text:        strings.Repeat("a", 1000001), // è¶…é 1MB é™åˆ¶
			expectError: true,
			description: "è¶…éæœ€å¤§é•·åº¦é™åˆ¶çš„æ–‡æœ¬",
		},
		{
			name:        "æ¥µå°éç©ºæ–‡æœ¬",
			text:        "a",
			expectError: false,
			description: "æœ€å°çš„éç©ºæ–‡æœ¬",
		},
		{
			name:        "åªæœ‰ç©ºç™½å­—ç¬¦",
			text:        "   \t\n\r   ",
			expectError: false,  
			description: "åªåŒ…å«å„ç¨®ç©ºç™½å­—ç¬¦",
		},
		{
			name:        "åªæœ‰æ¨™é»ç¬¦è™Ÿ",
			text:        "!@#$%^&*()_+-=[]{}|;':\",./<>?",
			expectError: false,
			description: "åªåŒ…å«æ¨™é»ç¬¦è™Ÿ",
		},
		{
			name:        "æ··åˆæ§åˆ¶å­—ç¬¦",
			text:        "text\x00\x01\x02text",
			expectError: false,
			description: "åŒ…å«å°‘é‡æ§åˆ¶å­—ç¬¦",
		},
		{
			name:        "éå¤šæ§åˆ¶å­—ç¬¦",
			text:        strings.Repeat("\x00\x01\x02", 50),
			expectError: true,
			description: "åŒ…å«éå¤šæ§åˆ¶å­—ç¬¦",
		},
		{
			name:        "æ¥µé•·å–®è©",
			text:        strings.Repeat("supercalifragilisticexpialidocious", 100),
			expectError: false,
			description: "æ¥µé•·çš„é‡è¤‡å–®è©",
		},
		{
			name:        "æ•¸å­—åºåˆ—",
			text:        strings.Repeat("1234567890", 1000),
			expectError: false,
			description: "é•·æ•¸å­—åºåˆ—",
		},
		{
			name:        "æ··åˆæ›è¡Œæ ¼å¼",
			text:        "Line1\nLine2\r\nLine3\rLine4",
			expectError: false,
			description: "ä¸åŒçš„æ›è¡Œç¬¦æ ¼å¼",
		},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			// æ¸¬è©¦åŸºæœ¬è¨ˆç®—
			tokens, err := calculator.CalculateTokens(tc.text, "estimation")
			
			if tc.expectError {
				if err == nil {
					// å¯èƒ½æ˜¯æ–‡æœ¬é©—è­‰éšæ®µçš„éŒ¯èª¤
					if calcImpl, ok := calculator.(*TokenCalculatorImpl); ok {
						err = calcImpl.ValidateText(tc.text)
						if err == nil {
							t.Errorf("é æœŸéŒ¯èª¤ä½†æ²’æœ‰ç™¼ç”Ÿ: %s", tc.description)
						}
					}
				}
				return
			}

			if err != nil {
				t.Errorf("æ„å¤–éŒ¯èª¤: %v", err)
				return
			}

			// é©—è­‰çµæœåˆç†æ€§
			if len(tc.text) > 0 && tokens <= 0 {
				t.Errorf("éç©ºæ–‡æœ¬æ‡‰è©²ç”¢ç”Ÿæ­£æ•¸ tokenï¼Œå¾—åˆ°: %d", tokens)
			}

			if len(tc.text) == 0 && tokens != 0 {
				t.Errorf("ç©ºæ–‡æœ¬æ‡‰è©²ç”¢ç”Ÿ 0 å€‹ tokenï¼Œå¾—åˆ°: %d", tokens)
			}

			t.Logf("%s: %d tokens (æ–‡æœ¬é•·åº¦: %d) - %s", 
				tc.name, tokens, len(tc.text), tc.description)
		})
	}
}

// TestConcurrentSafety æ¸¬è©¦ä½µç™¼å®‰å…¨æ€§
func TestConcurrentSafety(t *testing.T) {
	calculator := NewTokenCalculator(1000)
	
	texts := []string{
		"Hello world",
		"ä½ å¥½ä¸–ç•Œ",
		"Mixed content æ··åˆå…§å®¹",
		"function test() { return true; }",
		"æ¸¬è©¦ä½µç™¼å®‰å…¨æ€§çš„æ–‡æœ¬å…§å®¹",
	}

	var wg sync.WaitGroup
	errors := make(chan error, 100)
	results := make(chan int, 100)

	// å•Ÿå‹•å¤šå€‹ goroutine åŒæ™‚è¨ˆç®—
	for i := 0; i < 20; i++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()
			
			for j := 0; j < 10; j++ {
				text := texts[j%len(texts)]
				tokens, err := calculator.CalculateTokens(text, "estimation")
				
				if err != nil {
					errors <- fmt.Errorf("goroutine %d: %w", id, err)
					return
				}
				
				results <- tokens
			}
		}(i)
	}

	// ç­‰å¾…æ‰€æœ‰ goroutine å®Œæˆ
	go func() {
		wg.Wait()
		close(errors)
		close(results)
	}()

	// æª¢æŸ¥éŒ¯èª¤
	for err := range errors {
		t.Errorf("ä½µç™¼è¨ˆç®—éŒ¯èª¤: %v", err)
	}

	// æ”¶é›†çµæœ
	var resultCount int
	for range results {
		resultCount++
	}

	expectedResults := 20 * 10 // 20 å€‹ goroutineï¼Œæ¯å€‹è¨ˆç®— 10 æ¬¡
	if resultCount != expectedResults {
		t.Errorf("é æœŸ %d å€‹çµæœï¼Œå¯¦éš›å¾—åˆ° %d å€‹", expectedResults, resultCount)
	}

	// æ¸¬è©¦å¿«å–çµ±è¨ˆçš„ç·šç¨‹å®‰å…¨æ€§
	if calcImpl, ok := calculator.(*TokenCalculatorImpl); ok {
		stats := calcImpl.GetCacheStats()
		if cacheSize, ok := stats["cache_size"].(int); ok {
			t.Logf("ä½µç™¼æ¸¬è©¦å¾Œå¿«å–å¤§å°: %d", cacheSize)
		}
	}
}

// TestMemoryUsageAndLimits æ¸¬è©¦è¨˜æ†¶é«”ä½¿ç”¨å’Œé™åˆ¶
func TestMemoryUsageAndLimits(t *testing.T) {
	// å‰µå»ºå°å¿«å–çš„è¨ˆç®—å™¨ä¾†æ¸¬è©¦è¨˜æ†¶é«”é™åˆ¶
	calculator := NewTokenCalculator(10)
	
	// è¨˜éŒ„åˆå§‹è¨˜æ†¶é«”ä½¿ç”¨
	var m1, m2 runtime.MemStats
	runtime.GC()
	runtime.ReadMemStats(&m1)

	// ç”Ÿæˆå¤§é‡ä¸åŒçš„æ–‡æœ¬ä¾†å¡«å……å¿«å–
	texts := make([]string, 50)
	for i := 0; i < 50; i++ {
		texts[i] = fmt.Sprintf("æ¸¬è©¦æ–‡æœ¬ %d: %s", i, strings.Repeat("test ", i+1))
	}

	// è¨ˆç®—æ‰€æœ‰æ–‡æœ¬çš„ token
	for _, text := range texts {
		_, err := calculator.CalculateTokens(text, "estimation")
		if err != nil {
			t.Errorf("è¨ˆç®—å¤±æ•—: %v", err)
		}
	}

	// æª¢æŸ¥å¿«å–æ˜¯å¦æŒ‰é æœŸé™åˆ¶å¤§å°
	if calcImpl, ok := calculator.(*TokenCalculatorImpl); ok {
		stats := calcImpl.GetCacheStats()
		cacheSize := stats["cache_size"].(int)
		maxCacheSize := stats["max_cache_size"].(int)
		
		if cacheSize > maxCacheSize {
			t.Errorf("å¿«å–å¤§å° %d è¶…éæœ€å¤§é™åˆ¶ %d", cacheSize, maxCacheSize)
		}
		
		t.Logf("å¿«å–çµ±è¨ˆ: %+v", stats)
	}

	// è¨˜éŒ„æœ€çµ‚è¨˜æ†¶é«”ä½¿ç”¨
	runtime.GC()
	runtime.ReadMemStats(&m2)

	memoryIncrease := m2.Alloc - m1.Alloc
	t.Logf("è¨˜æ†¶é«”ä½¿ç”¨å¢åŠ : %d bytes", memoryIncrease)

	// é©—è­‰è¨˜æ†¶é«”ä½¿ç”¨åœ¨åˆç†ç¯„åœå…§ï¼ˆé€™æ˜¯ä¸€å€‹è»Ÿæ€§æª¢æŸ¥ï¼‰
	if memoryIncrease > 10*1024*1024 { // 10MB
		t.Logf("è­¦å‘Š: è¨˜æ†¶é«”ä½¿ç”¨å¢åŠ è¼ƒå¤š: %d bytes", memoryIncrease)
	}
}

// TestPerformanceBenchmarks æ“´å±•çš„æ•ˆèƒ½åŸºæº–æ¸¬è©¦
func TestPerformanceBenchmarks(t *testing.T) {
	calculator := NewTokenCalculator(1000)
	
	testTexts := []struct {
		name string
		text string
	}{
		{"çŸ­è‹±æ–‡", "Hello world"},
		{"çŸ­ä¸­æ–‡", "ä½ å¥½ä¸–ç•Œ"},
		{"ä¸­è‹±æ··åˆ", "Hello ä¸–ç•Œ testing æ¸¬è©¦"},
		{"é•·è‹±æ–‡", strings.Repeat("This is a test sentence. ", 100)},
		{"é•·ä¸­æ–‡", strings.Repeat("é€™æ˜¯ä¸€å€‹æ¸¬è©¦å¥å­ã€‚", 100)},
		{"ç¨‹å¼ç¢¼", strings.Repeat("function test() { return 'hello'; }\n", 50)},
		{"JSON", strings.Repeat(`{"key": "value", "number": 123}, `, 100)},
	}

	for _, tt := range testTexts {
		t.Run(fmt.Sprintf("Performance_%s", tt.name), func(t *testing.T) {
			start := time.Now()
			iterations := 1000
			
			for i := 0; i < iterations; i++ {
				_, err := calculator.CalculateTokens(tt.text, "estimation")
				if err != nil {
					t.Errorf("è¨ˆç®—å¤±æ•—: %v", err)
					return
				}
			}
			
			duration := time.Since(start)
			avgTime := duration / time.Duration(iterations)
			
			t.Logf("%s: %d æ¬¡è¨ˆç®—è€—æ™‚ %vï¼Œå¹³å‡ %v/æ¬¡", 
				tt.name, iterations, duration, avgTime)
			
			// æ•ˆèƒ½è¦æ±‚ï¼šæ¯æ¬¡è¨ˆç®—æ‡‰è©²åœ¨ 1ms ä»¥å…§
			if avgTime > time.Millisecond {
				t.Logf("è­¦å‘Š: æ•ˆèƒ½å¯èƒ½éœ€è¦å„ªåŒ–ï¼Œå¹³å‡æ™‚é–“: %v", avgTime)
			}
		})
	}
}

// TestCachePerformanceImprovement æ¸¬è©¦å¿«å–æ•ˆèƒ½æå‡
func TestCachePerformanceImprovement(t *testing.T) {
	calculator := NewTokenCalculator(1000)
	text := strings.Repeat("é€™æ˜¯ä¸€å€‹ç”¨æ–¼æ•ˆèƒ½æ¸¬è©¦çš„æ–‡æœ¬ Performance test text ", 50)
	iterations := 1000

	// æ¸¬è©¦æ²’æœ‰å¿«å–çš„æ•ˆèƒ½ï¼ˆæ¯æ¬¡éƒ½ç”¨ä¸åŒçš„æ–‡æœ¬ï¼‰
	start := time.Now()
	for i := 0; i < iterations; i++ {
		uniqueText := fmt.Sprintf("%s %d", text, i)
		calculator.CalculateTokens(uniqueText, "estimation")
	}
	noCacheDuration := time.Since(start)

	// æ¸¬è©¦æœ‰å¿«å–çš„æ•ˆèƒ½ï¼ˆé‡è¤‡ä½¿ç”¨ç›¸åŒæ–‡æœ¬ï¼‰
	start = time.Now()
	for i := 0; i < iterations; i++ {
		calculator.CalculateTokens(text, "estimation")
	}
	withCacheDuration := time.Since(start)

	// è¨ˆç®—æ•ˆèƒ½æå‡
	improvement := float64(noCacheDuration) / float64(withCacheDuration)
	
	t.Logf("ç„¡å¿«å–: %v", noCacheDuration)
	t.Logf("æœ‰å¿«å–: %v", withCacheDuration)
	t.Logf("æ•ˆèƒ½æå‡: %.2fx", improvement)

	// å¿«å–æ‡‰è©²é¡¯è‘—æå‡æ•ˆèƒ½
	if improvement < 2.0 {
		t.Logf("è­¦å‘Š: å¿«å–æ•ˆèƒ½æå‡ä¸å¤ æ˜é¡¯: %.2fx", improvement)
	}
}

// TestSensitiveDataProtection æ¸¬è©¦æ•æ„Ÿè³‡æ–™ä¿è­·
func TestSensitiveDataProtection(t *testing.T) {
	calculator := NewTokenCalculator(100)
	
	// æ¨¡æ“¬åŒ…å«æ•æ„Ÿè³‡è¨Šçš„æ–‡æœ¬
	sensitiveTexts := []string{
		"å¯†ç¢¼: admin123",
		"API Key: sk-1234567890abcdef",
		"ä¿¡ç”¨å¡è™Ÿ: 4111-1111-1111-1111",
		"èº«åˆ†è­‰å­—è™Ÿ: A123456789",
		"é›»è©±è™Ÿç¢¼: 0912-345-678",
		"é›»å­éƒµä»¶: user@example.com",
	}

	for _, text := range sensitiveTexts {
		t.Run(fmt.Sprintf("Sensitive_%s", text[:10]), func(t *testing.T) {
			// è¨ˆç®— Tokenï¼Œä¸æ‡‰è©²å‡ºéŒ¯
			tokens, err := calculator.CalculateTokens(text, "estimation")
			if err != nil {
				t.Errorf("è¨ˆç®—å¤±æ•—: %v", err)
				return
			}

			if tokens <= 0 {
				t.Errorf("æ‡‰è©²ç”¢ç”Ÿæ­£æ•¸ tokenï¼Œå¾—åˆ°: %d", tokens)
			}

			// é‡è¦ï¼šæª¢æŸ¥æ—¥èªŒä¸­ä¸æ‡‰è©²å‡ºç¾æ•æ„Ÿè³‡è¨Š
			// é€™è£¡æˆ‘å€‘æ¨¡æ“¬æª¢æŸ¥ï¼Œå¯¦éš›å¯¦ä½œä¸­æ‡‰è©²ç¢ºä¿æ•æ„Ÿè³‡è¨Šä¸æœƒè¨˜éŒ„åˆ°æ—¥èªŒ
			t.Logf("è™•ç†æ•æ„Ÿæ–‡æœ¬: %d tokens (é•·åº¦: %d)", tokens, len(text))
			
			// æ³¨æ„ï¼šé€™è£¡æˆ‘å€‘æ²’æœ‰è¨˜éŒ„å¯¦éš›çš„æ–‡æœ¬å…§å®¹ï¼Œä»¥ä¿è­·æ•æ„Ÿè³‡è¨Š
		})
	}
}

// BenchmarkExtendedTokenCalculation æ“´å±•çš„åŸºæº–æ¸¬è©¦
func BenchmarkExtendedTokenCalculation(b *testing.B) {
	calculator := NewTokenCalculator(1000)
	
	benchmarkCases := []struct {
		name string
		text string
	}{
		{"VeryShort", "Hi"},
		{"Short", "Hello world"},
		{"Medium", strings.Repeat("This is a test. ", 10)},
		{"Long", strings.Repeat("This is a longer test sentence. ", 100)},
		{"VeryLong", strings.Repeat("This is a very long test sentence for performance testing. ", 1000)},
		{"Chinese", strings.Repeat("é€™æ˜¯ä¸­æ–‡æ¸¬è©¦å¥å­ã€‚", 100)},
		{"Mixed", strings.Repeat("Mixed æ··åˆ content å…§å®¹ ", 100)},
		{"Code", strings.Repeat("func test() { return 'hello'; }\n", 100)},
	}

	for _, bc := range benchmarkCases {
		b.Run(bc.name, func(b *testing.B) {
			b.ResetTimer()
			for i := 0; i < b.N; i++ {
				calculator.CalculateTokens(bc.text, "estimation")
			}
		})
	}
}

// BenchmarkConcurrentCalculation ä½µç™¼è¨ˆç®—åŸºæº–æ¸¬è©¦
func BenchmarkConcurrentCalculation(b *testing.B) {
	calculator := NewTokenCalculator(1000)
	text := strings.Repeat("ä½µç™¼æ¸¬è©¦æ–‡æœ¬ Concurrent test text ", 50)

	b.RunParallel(func(pb *testing.PB) {
		for pb.Next() {
			calculator.CalculateTokens(text, "estimation")
		}
	})
}

// BenchmarkCacheEfficiency å¿«å–æ•ˆç‡åŸºæº–æ¸¬è©¦
func BenchmarkCacheEfficiency(b *testing.B) {
	calculator := NewTokenCalculator(1000)
	texts := []string{
		"Text 1 for cache test",
		"Text 2 for cache test", 
		"Text 3 for cache test",
		"Text 4 for cache test",
		"Text 5 for cache test",
	}

	// é ç†±å¿«å–
	for _, text := range texts {
		calculator.CalculateTokens(text, "estimation")
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		text := texts[i%len(texts)]
		calculator.CalculateTokens(text, "estimation")
	}
}