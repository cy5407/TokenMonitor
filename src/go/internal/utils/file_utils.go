package utils

import (
	"bufio"
	"compress/gzip"
	"crypto/md5"
	"encoding/hex"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	"time"
)

// FileInfo æª”æ¡ˆè³‡è¨Šçµæ§‹
type FileInfo struct {
	Path      string    `json:"path"`
	Size      int64     `json:"size"`
	ModTime   time.Time `json:"mod_time"`
	IsDir     bool      `json:"is_dir"`
	Extension string    `json:"extension"`
	MD5Hash   string    `json:"md5_hash,omitempty"`
	LineCount int       `json:"line_count,omitempty"`
	Encoding  string    `json:"encoding,omitempty"`
}

// FileProcessor æª”æ¡ˆè™•ç†å™¨
type FileProcessor struct {
	maxFileSize   int64
	allowedExts   []string
	excludeDirs   []string
	enableHashing bool
}

// NewFileProcessor å»ºç«‹æª”æ¡ˆè™•ç†å™¨
func NewFileProcessor() *FileProcessor {
	return &FileProcessor{
		maxFileSize:   100 * 1024 * 1024, // 100MB
		allowedExts:   []string{".txt", ".log", ".json", ".csv", ".md"},
		excludeDirs:   []string{".git", "node_modules", ".kiro"},
		enableHashing: true,
	}
}

// SetMaxFileSize è¨­å®šæœ€å¤§æª”æ¡ˆå¤§å°
func (fp *FileProcessor) SetMaxFileSize(size int64) {
	fp.maxFileSize = size
}

// SetAllowedExtensions è¨­å®šå…è¨±çš„å‰¯æª”å
func (fp *FileProcessor) SetAllowedExtensions(exts []string) {
	fp.allowedExts = exts
}

// SetExcludeDirs è¨­å®šæ’é™¤çš„ç›®éŒ„
func (fp *FileProcessor) SetExcludeDirs(dirs []string) {
	fp.excludeDirs = dirs
}

// ScanDirectory æƒæç›®éŒ„
func (fp *FileProcessor) ScanDirectory(rootPath string) ([]FileInfo, error) {
	var files []FileInfo

	err := filepath.Walk(rootPath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		// è·³éæ’é™¤çš„ç›®éŒ„
		if info.IsDir() && fp.shouldExcludeDir(info.Name()) {
			return filepath.SkipDir
		}

		// è™•ç†æª”æ¡ˆ
		if !info.IsDir() {
			fileInfo, err := fp.processFile(path, info)
			if err != nil {
				// è¨˜éŒ„éŒ¯èª¤ä½†ç¹¼çºŒè™•ç†
				fmt.Printf("âš ï¸  è™•ç†æª”æ¡ˆå¤±æ•— %s: %v\n", path, err)
				return nil
			}

			if fileInfo != nil {
				files = append(files, *fileInfo)
			}
		}

		return nil
	})

	return files, err
}

// processFile è™•ç†å–®å€‹æª”æ¡ˆ
func (fp *FileProcessor) processFile(path string, info os.FileInfo) (*FileInfo, error) {
	// æª¢æŸ¥æª”æ¡ˆå¤§å°
	if info.Size() > fp.maxFileSize {
		return nil, fmt.Errorf("æª”æ¡ˆéå¤§: %d bytes", info.Size())
	}

	// æª¢æŸ¥å‰¯æª”å
	ext := strings.ToLower(filepath.Ext(path))
	if !fp.isAllowedExtension(ext) {
		return nil, nil // è·³éä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹
	}

	fileInfo := &FileInfo{
		Path:      path,
		Size:      info.Size(),
		ModTime:   info.ModTime(),
		IsDir:     info.IsDir(),
		Extension: ext,
	}

	// è¨ˆç®— MD5 é›œæ¹Š
	if fp.enableHashing {
		hash, err := fp.calculateMD5(path)
		if err != nil {
			return nil, fmt.Errorf("è¨ˆç®— MD5 å¤±æ•—: %w", err)
		}
		fileInfo.MD5Hash = hash
	}

	// è¨ˆç®—è¡Œæ•¸
	if fp.isTextFile(ext) {
		lineCount, encoding, err := fp.analyzeTextFile(path)
		if err != nil {
			return nil, fmt.Errorf("åˆ†ææ–‡å­—æª”æ¡ˆå¤±æ•—: %w", err)
		}
		fileInfo.LineCount = lineCount
		fileInfo.Encoding = encoding
	}

	return fileInfo, nil
}

// shouldExcludeDir æª¢æŸ¥æ˜¯å¦æ‡‰æ’é™¤ç›®éŒ„
func (fp *FileProcessor) shouldExcludeDir(dirName string) bool {
	for _, excludeDir := range fp.excludeDirs {
		if dirName == excludeDir {
			return true
		}
	}
	return false
}

// isAllowedExtension æª¢æŸ¥æ˜¯å¦ç‚ºå…è¨±çš„å‰¯æª”å
func (fp *FileProcessor) isAllowedExtension(ext string) bool {
	for _, allowedExt := range fp.allowedExts {
		if ext == allowedExt {
			return true
		}
	}
	return false
}

// isTextFile æª¢æŸ¥æ˜¯å¦ç‚ºæ–‡å­—æª”æ¡ˆ
func (fp *FileProcessor) isTextFile(ext string) bool {
	textExts := []string{".txt", ".log", ".md", ".json", ".csv", ".yaml", ".yml"}
	for _, textExt := range textExts {
		if ext == textExt {
			return true
		}
	}
	return false
}

// calculateMD5 è¨ˆç®—æª”æ¡ˆ MD5 é›œæ¹Š
func (fp *FileProcessor) calculateMD5(filePath string) (string, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return "", err
	}
	defer file.Close()

	hash := md5.New()
	if _, err := io.Copy(hash, file); err != nil {
		return "", err
	}

	return hex.EncodeToString(hash.Sum(nil)), nil
}

// analyzeTextFile åˆ†ææ–‡å­—æª”æ¡ˆ
func (fp *FileProcessor) analyzeTextFile(filePath string) (int, string, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return 0, "", err
	}
	defer file.Close()

	scanner := bufio.NewScanner(file)
	lineCount := 0
	encoding := "UTF-8" // é è¨­ç·¨ç¢¼

	// è®€å–å‰å¹¾è¡Œä¾†æª¢æ¸¬ç·¨ç¢¼
	sampleLines := 0
	for scanner.Scan() && sampleLines < 10 {
		line := scanner.Text()

		// ç°¡å–®çš„ç·¨ç¢¼æª¢æ¸¬
		if !isValidUTF8(line) {
			encoding = "Unknown"
		}

		lineCount++
		sampleLines++
	}

	// ç¹¼çºŒè¨ˆç®—å‰©é¤˜è¡Œæ•¸
	for scanner.Scan() {
		lineCount++
	}

	if err := scanner.Err(); err != nil {
		return lineCount, encoding, err
	}

	return lineCount, encoding, nil
}

// isValidUTF8 æª¢æŸ¥å­—ä¸²æ˜¯å¦ç‚ºæœ‰æ•ˆçš„ UTF-8
func isValidUTF8(s string) bool {
	return strings.ToValidUTF8(s, "") == s
}

// CompressFile å£“ç¸®æª”æ¡ˆ
func CompressFile(srcPath, dstPath string) error {
	srcFile, err := os.Open(srcPath)
	if err != nil {
		return err
	}
	defer srcFile.Close()

	dstFile, err := os.Create(dstPath)
	if err != nil {
		return err
	}
	defer dstFile.Close()

	gzWriter := gzip.NewWriter(dstFile)
	defer gzWriter.Close()

	_, err = io.Copy(gzWriter, srcFile)
	return err
}

// DecompressFile è§£å£“ç¸®æª”æ¡ˆ
func DecompressFile(srcPath, dstPath string) error {
	srcFile, err := os.Open(srcPath)
	if err != nil {
		return err
	}
	defer srcFile.Close()

	gzReader, err := gzip.NewReader(srcFile)
	if err != nil {
		return err
	}
	defer gzReader.Close()

	dstFile, err := os.Create(dstPath)
	if err != nil {
		return err
	}
	defer dstFile.Close()

	_, err = io.Copy(dstFile, gzReader)
	return err
}

// CopyFile è¤‡è£½æª”æ¡ˆ
func CopyFile(srcPath, dstPath string) error {
	srcFile, err := os.Open(srcPath)
	if err != nil {
		return err
	}
	defer srcFile.Close()

	// ç¢ºä¿ç›®æ¨™ç›®éŒ„å­˜åœ¨
	dstDir := filepath.Dir(dstPath)
	if err := os.MkdirAll(dstDir, 0755); err != nil {
		return err
	}

	dstFile, err := os.Create(dstPath)
	if err != nil {
		return err
	}
	defer dstFile.Close()

	_, err = io.Copy(dstFile, srcFile)
	return err
}

// MoveFile ç§»å‹•æª”æ¡ˆ
func MoveFile(srcPath, dstPath string) error {
	// å…ˆå˜—è©¦é‡æ–°å‘½åï¼ˆåŒä¸€æª”æ¡ˆç³»çµ±ï¼‰
	if err := os.Rename(srcPath, dstPath); err == nil {
		return nil
	}

	// å¦‚æœé‡æ–°å‘½åå¤±æ•—ï¼Œå‰‡è¤‡è£½å¾Œåˆªé™¤
	if err := CopyFile(srcPath, dstPath); err != nil {
		return err
	}

	return os.Remove(srcPath)
}

// EnsureDir ç¢ºä¿ç›®éŒ„å­˜åœ¨
func EnsureDir(dirPath string) error {
	return os.MkdirAll(dirPath, 0755)
}

// CleanupOldFiles æ¸…ç†èˆŠæª”æ¡ˆ
func CleanupOldFiles(dirPath string, maxAge time.Duration) error {
	cutoffTime := time.Now().Add(-maxAge)

	return filepath.Walk(dirPath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		if !info.IsDir() && info.ModTime().Before(cutoffTime) {
			fmt.Printf("ğŸ—‘ï¸  åˆªé™¤èˆŠæª”æ¡ˆ: %s\n", path)
			return os.Remove(path)
		}

		return nil
	})
}

// GetDirSize ç²å–ç›®éŒ„å¤§å°
func GetDirSize(dirPath string) (int64, error) {
	var size int64

	err := filepath.Walk(dirPath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		if !info.IsDir() {
			size += info.Size()
		}

		return nil
	})

	return size, err
}

// FindDuplicateFiles å°‹æ‰¾é‡è¤‡æª”æ¡ˆ
func FindDuplicateFiles(dirPath string) (map[string][]string, error) {
	fp := NewFileProcessor()
	files, err := fp.ScanDirectory(dirPath)
	if err != nil {
		return nil, err
	}

	hashMap := make(map[string][]string)

	for _, file := range files {
		if file.MD5Hash != "" {
			hashMap[file.MD5Hash] = append(hashMap[file.MD5Hash], file.Path)
		}
	}

	// åªè¿”å›æœ‰é‡è¤‡çš„æª”æ¡ˆ
	duplicates := make(map[string][]string)
	for hash, paths := range hashMap {
		if len(paths) > 1 {
			duplicates[hash] = paths
		}
	}

	return duplicates, nil
}
